{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First let's read all data and create dataframes from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in json line data and create dataframes\n",
    "companies_info = []\n",
    "with open('/home/huynhhao/Desktop/job_recommender/crawl_data/companies_info.jl', 'r', encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "        company_info = json.loads(line)\n",
    "        companies_info.append(company_info)\n",
    "        \n",
    "# create a companies dataframe\n",
    "companies_df = pd.DataFrame([], columns = ['company_id', 'company_name', 'average_rating', 'num_review' ,\n",
    "                                           'city', 'type', 'num_employee',  'country', 'working_day', 'OT', \n",
    "                                           'overview','expertise', 'benifit', 'logo_link' ])\n",
    "for company in companies_info:\n",
    "    companies_df = companies_df.append({'company_id': company['company_name'], \n",
    "                                       'company_name': company['name'],\n",
    "                                        'average_rating': company['average_rating'],\n",
    "                                        'num_review': company['num_review'],\n",
    "                                       'city': company['city'],\n",
    "                                       'type': company['type'], \n",
    "                                       'num_employee': company['num_employee'], \n",
    "                                       'country': company['country'],\n",
    "                                       'working_day': company['working_day'], \n",
    "                                       'OT': company['OT'], \n",
    "                                       'overview': company['overview'],\n",
    "                                        'expertise': company['expertise'],\n",
    "                                        'benifit': company['benifit'],\n",
    "                                       'logo_link': company['logo']},\n",
    "                                      ignore_index = True)\n",
    "    \n",
    "    \n",
    "\n",
    "jobs_info = []\n",
    "with open('/home/huynhhao/Desktop/job_recommender/crawl_data/job_info.jl', 'r', encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "        job = json.loads(line)\n",
    "        jobs_info.append(job)\n",
    "        \n",
    "# job_info dataframe\n",
    "jobs_df = pd.DataFrame([], columns = ['company_id', 'job_name', 'taglist', 'location', 'three_reasons', 'description'])\n",
    "for job in jobs_info:\n",
    "    jobs_df = jobs_df.append({'company_id': job['company_name'],\n",
    "                             'job_name': job['job_name'],\n",
    "                             'taglist': job['tag_list'],\n",
    "                             'location': job['location'],\n",
    "                             'three_reasons': job['three_reasons'],\n",
    "                             'description': job['description']},\n",
    "                             ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "compaines_df = companies_df.fillna('')\n",
    "jobs_df = jobs_df.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll preprocess all text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(text: str, replaced: str = '\\n') -> str:\n",
    "    # remove all html tags in text and return the without-html-tag text\n",
    "    if text is not None:\n",
    "        return re.sub(r'<.*?>', replaced, text ).strip()\n",
    "    return ''\n",
    "for i in range(len(companies_df)):\n",
    "    companies_df.loc[i, 'overview'] = remove_tags(companies_df.loc[i, 'overview'])\n",
    "    companies_df.loc[i, 'expertise'] = remove_tags(companies_df.loc[i, 'expertise'])\n",
    "#     print(companies_df.loc[i, 'benifit'])\n",
    "    companies_df.loc[i, 'benifit'] = remove_tags(companies_df.loc[i, 'benifit'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess jobs_df\n",
    "for i in range(len(jobs_df)):\n",
    "    jobs_df.loc[i, 'three_reasons'] = remove_tags(jobs_df.loc[i, 'three_reasons'])\n",
    "    jobs_df.loc[i, 'description'] = remove_tags(jobs_df.loc[i, 'description'])\n",
    "    jobs_df.loc[i, 'taglist'] = ' '.join(' '.join(jobs_df.loc[i, 'taglist'].split('\\n')).split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all the company ids in jobs_df dataframe are actually from the company ids in companies_df dataframe\n",
    "# which means you don't have a job that is posted by a non-existed company!\n",
    "set(jobs_df.loc[:, 'company_id'].values).issubset(set(companies_df.loc[:, 'company_id'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So far so good, the preprocessing of companies_df and jobs_df are done here, the remaining works will be left to the user of these dataframe. Let's save them and moving to preprocess the CV dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_df_path = '/home/huynhhao/Desktop/job_recommender/data/companies.csv'\n",
    "jobs_df_path = '/home/huynhhao/Desktop/job_recommender/data/jobs.csv'\n",
    "companies_df.to_csv(companies_df_path, index = False, encoding = 'utf-8')\n",
    "jobs_df.to_csv(jobs_df_path, index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14e85d4a77190ddb21ca04761e6fe918abc9f382c46a2b12fd65738fd607c258"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
